# Config for web-rwkv-axum
# It specifies what model to use, what token table to use, etc.

[model]
# Path to the model file
# Must be a safetensor instead of pth.
path = "assets/RWKV-4-World-0.4B-v1-20230529-ctx4096.st"
# Max batch count means max concurrent tasks will the
# model infer at once. Default 32.
max_batch_count = 32
# Max chunk count means how many tokens should a chunk
# be at max. Larger chunks increase infer speed for long
# prompt at the cost of resource consumption.
max_chunk_count = 256
# Preference for adapter. Can be HighPerformance or
# LowPower. If omitted, adapter index will be used.
preference = "HighPerformance"
# Adapter index to select, usually 0.
# There might be a tool to check for adapters later.
# adapter = 0
# Quantize a certain layer of the model, a bit flag.
# If omitted, no quantization is done.
# quantization = 1

[tokenizer]
# Path to the vocab JSON.
# Refer to https://github.com/cryscan/web-rwkv/blob/main/assets/rwkv_vocab_v20230424.json
path = "assets/rwkv_vocab_v20230424.json"